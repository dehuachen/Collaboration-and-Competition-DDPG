{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration and Competition\n",
    "\n",
    "---\n",
    "\n",
    "You are welcome to use this coding environment to train your agent for the project.  Follow the instructions below to get started!\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "Run the next code cell to install a few packages.  This line will take a few minutes to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mtensorflow 1.7.1 has requirement numpy>=1.13.3, but you'll have numpy 1.12.1 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mipython 6.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.15, but you'll have prompt-toolkit 3.0.36 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mjupyter-console 6.4.3 has requirement jupyter-client>=7.0.0, but you'll have jupyter-client 5.2.4 which is incompatible.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip -q install ./python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environment is already saved in the Workspace and can be accessed at the file path provided below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "env = UnityEnvironment(file_name=\"/data/Tennis_Linux_NoVis/Tennis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.         -6.65278625 -1.5        -0.          0.\n",
      "  6.83172083  6.         -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents \n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Note that **in this coding environment, you will not be able to watch the agents while they are training**, and you should set `train_mode=True` to restart the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_sum = np.zeros((2,24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score (averaged over agents) this episode: -0.004999999888241291\n",
      "Total score (averaged over agents) this episode: -0.004999999888241291\n",
      "Total score (averaged over agents) this episode: -0.004999999888241291\n",
      "Total score (averaged over agents) this episode: -0.004999999888241291\n",
      "Total score (averaged over agents) this episode: -0.004999999888241291\n"
     ]
    }
   ],
   "source": [
    "rewards_l = []\n",
    "for i in range(5):                                         # play game for 5 episodes\n",
    "    env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "    states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "    scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "\n",
    "    while True:\n",
    "        state_sum += states\n",
    "        actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "        actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "        env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "        next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "        rewards = env_info.rewards                         # get reward (for each agent)\n",
    "        rewards_l.append(rewards)\n",
    "        dones = env_info.local_done                        # see if episode finished\n",
    "        scores += env_info.rewards                         # update the score (for each agent)\n",
    "        states = next_states                               # roll over states to next time step\n",
    "        if np.any(dones):                                  # exit loop if episode finished\n",
    "            break\n",
    "    print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OUNoise:\n",
    "    \"\"\"Ornstein-Uhlenbeck process.\"\"\"\n",
    "\n",
    "    def __init__(self, size, seed, mu=0.0, theta=0.1, sigma=0.5):\n",
    "        \"\"\"Initialize parameters and noise process.\"\"\"\n",
    "        self.mu = mu * np.ones(size)\n",
    "        self.theta = theta\n",
    "        self.sigma = sigma\n",
    "        self.seed = random.seed(seed)\n",
    "        self.size = size\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset the internal state (= noise) to mean (mu).\"\"\"\n",
    "        self.state = copy.copy(self.mu)\n",
    "        self.sigma *= 0.99\n",
    "        self.sigma = max(0.05, self.sigma)\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"Update internal state and return it as a noise sample.\"\"\"\n",
    "        x = self.state\n",
    "        dx = self.theta * (self.mu - x) + self.sigma * np.random.randn(1)\n",
    "        self.state = x + dx\n",
    "        return self.state\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, action_size, buffer_size, batch_size, seed):\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=buffer_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.experience = namedtuple(\n",
    "            'Experience', \n",
    "            field_names=['state', 'action', 'reward', 'next_state', 'done']\n",
    "        )\n",
    "        self.seed = random.seed(seed)\n",
    "\n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "        self.memory.append(e)\n",
    "    \n",
    "    def sample(self):\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "\n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).float().to(device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
    "    \n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hidden_init(layer):\n",
    "    fan_in = layer.weight.data.size(0)\n",
    "    lim = 1.0 / np.sqrt(fan_in)\n",
    "    return (-lim, lim)\n",
    "\n",
    "class Actor(nn.Module):\n",
    "    \n",
    "    def __init__(self, state_size, action_size, seed, layers=[256, 128]) -> None:\n",
    "        super(Actor, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        \n",
    "        self.fc1 = nn.Linear(state_size*2, layers[0])\n",
    "        self.fc2 = nn.Linear(layers[0], layers[1])\n",
    "        self.fc3 = nn.Linear(layers[1], action_size)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.fc1.weight.data.uniform_(*hidden_init(self.fc1))\n",
    "        self.fc2.weight.data.uniform_(*hidden_init(self.fc2))\n",
    "        self.fc3.weight.data.uniform_(-3e-3, 3e-3)\n",
    "    \n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.tanh(self.fc3(x))\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    \n",
    "    def __init__(self, state_size, action_size, seed, layers=[256, 128]) -> None:\n",
    "        super(Critic, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "\n",
    "        self.fcs1 = nn.Linear(state_size*2, layers[0])\n",
    "        self.fc2 = nn.Linear(layers[0] + action_size*2, layers[1])\n",
    "        self.fc3 = nn.Linear(layers[1], 1)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.fcs1.weight.data.uniform_(*hidden_init(self.fcs1))\n",
    "        self.fc2.weight.data.uniform_(*hidden_init(self.fc2))\n",
    "        self.fc3.weight.data.uniform_(-3e-3, 3e-3)\n",
    "    \n",
    "    def forward(self, state, action):\n",
    "        x = F.relu(self.fcs1(state))\n",
    "        x = torch.cat([x, action], dim=1)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = int(1e5)  # replay buffer size\n",
    "BATCH_SIZE = 128        # minibatch size\n",
    "GAMMA = 0.99            # discount factor\n",
    "TAU = 1e-3              # for soft update of target parameters\n",
    "LR_ACTOR = 1e-3         # learning rate of the actor \n",
    "LR_CRITIC = 1e-3        # learning rate of the critic\n",
    "WEIGHT_DECAY = 0        # L2 weight decay\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, state_size, action_size, random_seed, agent_id, memory=None) -> None:\n",
    "        \n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.seed = random.seed(random_seed)\n",
    "        self.agent_id = agent_id\n",
    "\n",
    "        self.actor_local = Actor(state_size, action_size, random_seed).to(device)\n",
    "        self.actor_target = Actor(state_size, action_size, random_seed).to(device)\n",
    "        self.actor_opt = optim.Adam(self.actor_local.parameters(), lr=LR_ACTOR)\n",
    "\n",
    "        self.critic_local = Critic(state_size, action_size, random_seed).to(device)\n",
    "        self.critic_target = Critic(state_size, action_size, random_seed).to(device)\n",
    "        self.critic_opt = optim.Adam(self.critic_local.parameters(), lr=LR_CRITIC, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "        self.soft_update(self.actor_local, self.actor_target, 1)\n",
    "        self.soft_update(self.critic_local, self.critic_target, 1)\n",
    "        \n",
    "        self.noise = OUNoise((1, action_size), random_seed)\n",
    "        \n",
    "        self.memory = memory\n",
    "        if self.memory is None:\n",
    "            self.memory = ReplayBuffer(action_size, BUFFER_SIZE, BATCH_SIZE, random_seed)\n",
    "        \n",
    "        self.reset()\n",
    "\n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "        self.memory.add(state, action, reward, next_state, done)\n",
    "        \n",
    "        if len(self.memory) > BATCH_SIZE:\n",
    "            experiences = self.memory.sample()\n",
    "            self.learn(experiences, GAMMA)\n",
    "\n",
    "    def learn(self, experiences, gamma):\n",
    "        state, action, reward, next_state, done = experiences\n",
    "        \n",
    "        # critic\n",
    "        action_next = self.actor_target(next_state)\n",
    "#         print(action_next, action_next.shape)\n",
    "#         print(action, action.shape)\n",
    "        if self.agent_id == 0:\n",
    "            action_next = torch.cat((action_next, action[:, 2:]), dim=-1)\n",
    "        else:\n",
    "            action_next = torch.cat((action[:, :2], action_next), dim=-1)\n",
    "        \n",
    "        Q_targets_next = self.critic_target(next_state, action_next)\n",
    "        Q_targets = reward + (gamma * Q_targets_next * (1 - done))\n",
    "        Q_expected = self.critic_local(state, action)\n",
    "        critic_loss = F.mse_loss(Q_expected, Q_targets)\n",
    "        self.critic_opt.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.critic_local.parameters(), 1)\n",
    "        self.critic_opt.step()\n",
    "\n",
    "        # actor\n",
    "        action_pred = self.actor_local(state)\n",
    "        if self.agent_id == 0:\n",
    "            action_pred = torch.cat((action_pred, action[:,2:]), dim=1)\n",
    "        else:\n",
    "            action_pred = torch.cat((action[:,:2], action_pred), dim=1)\n",
    "        \n",
    "        actor_loss = -self.critic_local(state, action_pred).mean()\n",
    "        # Minimize the loss\n",
    "        self.actor_opt.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        self.actor_opt.step()\n",
    "\n",
    "        self.soft_update(self.critic_local, self.critic_target, TAU)\n",
    "        self.soft_update(self.actor_local, self.actor_target, TAU)\n",
    "\n",
    "    def act(self, state, add_noise=True, noise_rate=0.0):\n",
    "        \"\"\"\n",
    "        docstring\n",
    "        \"\"\"\n",
    "        state = torch.from_numpy(state).float().to(device)\n",
    "        self.actor_local.eval()\n",
    "        with torch.no_grad():\n",
    "            action = self.actor_local(state).cpu().numpy()\n",
    "        self.actor_local.train()\n",
    "        if add_noise:\n",
    "            action += self.noise.sample() #self.noise.sample()\n",
    "        return np.clip(action, -1, 1)\n",
    "\n",
    "    def reset(self):\n",
    "        self.noise.reset()\n",
    "    \n",
    "    def soft_update(self, local, target, tau):\n",
    "        for target_param, local_param in zip (target.parameters(), local.parameters()):\n",
    "            target_param.data.copy_(tau * local_param.data + (1.0 - tau) * target_param.data)\n",
    "\n",
    "\n",
    "class MultiAgent:\n",
    "\n",
    "    def __init__(self, state_size, action_size, random_seed) -> None:\n",
    "        self.action_size = action_size\n",
    "        self.noise_decay = 0.99\n",
    "        self.min_noise = 0.05\n",
    "\n",
    "        self.agent1 = Agent(state_size, action_size, random_seed, agent_id=0)\n",
    "        self.agent2 = Agent(state_size, action_size, random_seed, agent_id=1)\n",
    "\n",
    "    def act(self, state, add_noise=True):\n",
    "        \"\"\"\n",
    "        docstring\n",
    "        \"\"\"\n",
    "        state1 = np.reshape(state, (1, 48))\n",
    "        state2 = state1.copy()\n",
    "\n",
    "        action1 = self.agent1.act(state1, add_noise)\n",
    "        action2 = self.agent2.act(state2, add_noise)\n",
    "\n",
    "        actions = np.concatenate([action1, action2], axis=0).flatten()\n",
    "        assert len(actions.shape) == 1\n",
    "        return actions\n",
    "    \n",
    "    def step(self, state, action, reward, next_state, done, ep_i):\n",
    "        self.agent1.step(state, action, reward[0], next_state, done[0])\n",
    "        self.agent2.step(state, action, reward[1], next_state, done[1])\n",
    "\n",
    "    def reset(self):\n",
    "        self.agent1.reset()\n",
    "        self.agent2.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = MultiAgent(24, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: 0.00200000\n",
      "Episode 200\tAverage Score: 0.00000000\n",
      "Episode 300\tAverage Score: 0.00400000\n",
      "Episode 400\tAverage Score: 0.02100000\n",
      "Episode 500\tAverage Score: 0.01100000\n",
      "Episode 600\tAverage Score: 0.00100000\n",
      "Episode 700\tAverage Score: 0.00100000\n",
      "Episode 800\tAverage Score: 0.01200000\n",
      "Episode 900\tAverage Score: 0.03900000\n",
      "Episode 1000\tAverage Score: 0.07500000\n",
      "Episode 1100\tAverage Score: 0.05690000\n",
      "Episode 1200\tAverage Score: 0.08790000\n",
      "Episode 1300\tAverage Score: 0.12200000\n",
      "Episode 1400\tAverage Score: 0.11400000\n",
      "Episode 1500\tAverage Score: 0.14100000\n",
      "Episode 1600\tAverage Score: 0.17100000\n",
      "Episode 1700\tAverage Score: 0.17000000\n",
      "Episode 1800\tAverage Score: 0.16100000\n",
      "Episode 1900\tAverage Score: 0.17580000\n",
      "Episode 2000\tAverage Score: 0.24890000\n",
      "Episode 2100\tAverage Score: 0.25700000\n",
      "Episode 2200\tAverage Score: 0.06900000\n",
      "Episode 2300\tAverage Score: 0.11800000\n",
      "Episode 2400\tAverage Score: 0.25400000\n",
      "Episode 2500\tAverage Score: 0.22690000\n",
      "Episode 2600\tAverage Score: 0.22690000\n",
      "Episode 2700\tAverage Score: 0.22290000\n",
      "Episode 2800\tAverage Score: 0.29000000\n",
      "Episode 2900\tAverage Score: 0.32590000\n",
      "Episode 3000\tAverage Score: 0.29800000\n"
     ]
    }
   ],
   "source": [
    "def ddpg(n_episodes=1000, print_every=100, add_noise=True):\n",
    "    scores_deque = deque(maxlen=print_every)\n",
    "    scores = []\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        agent.reset()\n",
    "        state = env_info.vector_observations\n",
    "        state = np.reshape(state, (1, 48))\n",
    "\n",
    "        score = np.zeros(2)\n",
    "        while True:\n",
    "            action = agent.act(state, add_noise=add_noise)\n",
    "            env_info = env.step(action)[brain_name]\n",
    "            next_state = env_info.vector_observations\n",
    "            next_state = np.reshape(next_state, (1, 48))\n",
    "            reward = env_info.rewards\n",
    "            done = env_info.local_done\n",
    "\n",
    "            agent.step(state, action, reward, next_state, done, i_episode)\n",
    "            state = next_state\n",
    "            score += np.max(reward)\n",
    "            if np.any(done):\n",
    "                break\n",
    "        max_score = np.max(score)\n",
    "        scores_deque.append(max_score)\n",
    "        scores.append(max_score)\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.8f}'.format(i_episode, np.mean(scores_deque)), end=\"\")\n",
    "        torch.save(agent.agent1.actor_local.state_dict(), 'checkpoint_actor1.pth')\n",
    "        torch.save(agent.agent2.actor_local.state_dict(), 'checkpoint_actor2.pth')\n",
    "        torch.save(agent.agent1.critic_local.state_dict(), 'checkpoint_critic1.pth')\n",
    "        torch.save(agent.agent2.critic_local.state_dict(), 'checkpoint_critic2.pth')\n",
    "        if i_episode % print_every == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.8f}'.format(i_episode, np.mean(scores_deque)))\n",
    "        if np.mean(scores_deque) > 0.5: break\n",
    "            \n",
    "    return scores\n",
    "\n",
    "# scores = ddpg(n_episodes=1000)\n",
    "\n",
    "scores = ddpg(n_episodes=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2e305235f8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: 0.22200000\n",
      "Episode 200\tAverage Score: 0.38900001\n",
      "Episode 300\tAverage Score: 0.35090001\n",
      "Episode 324\tAverage Score: 0.50200001"
     ]
    }
   ],
   "source": [
    "def ddpg(n_episodes=1000, print_every=100, add_noise=True):\n",
    "    scores_deque = deque(maxlen=print_every)\n",
    "    scores = []\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        agent.reset()\n",
    "        state = env_info.vector_observations\n",
    "        state = np.reshape(state, (1, 48))\n",
    "\n",
    "        score = np.zeros(2)\n",
    "        while True:\n",
    "            action = agent.act(state, add_noise=add_noise)\n",
    "            env_info = env.step(action)[brain_name]\n",
    "            next_state = env_info.vector_observations\n",
    "            next_state = np.reshape(next_state, (1, 48))\n",
    "            reward = env_info.rewards\n",
    "            done = env_info.local_done\n",
    "\n",
    "            agent.step(state, action, reward, next_state, done, i_episode)\n",
    "            state = next_state\n",
    "            score += np.max(reward)\n",
    "            if np.any(done):\n",
    "                break\n",
    "        max_score = np.max(score)\n",
    "        scores_deque.append(max_score)\n",
    "        scores.append(max_score)\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.8f}'.format(i_episode, np.mean(scores_deque)), end=\"\")\n",
    "        torch.save(agent.agent1.actor_local.state_dict(), 'checkpoint_actor1.pth')\n",
    "        torch.save(agent.agent2.actor_local.state_dict(), 'checkpoint_actor2.pth')\n",
    "        torch.save(agent.agent1.critic_local.state_dict(), 'checkpoint_critic1.pth')\n",
    "        torch.save(agent.agent2.critic_local.state_dict(), 'checkpoint_critic2.pth')\n",
    "        if i_episode % print_every == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.8f}'.format(i_episode, np.mean(scores_deque)))\n",
    "        if np.mean(scores_deque) > 0.5: break\n",
    "            \n",
    "    return scores\n",
    "\n",
    "# scores = ddpg(n_episodes=1000)\n",
    "\n",
    "scores_ = ddpg(n_episodes=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2e247d79b0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores) + len(scores_)), scores + scores_)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
